{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] The derivatives are not implemented in fully vectorized way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkopersk/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pymlearn.linear\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pymlearn.linear' from '../pymlearn/linear.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(pymlearn.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set = datasets.load_digits(10)\n",
    "test_set_size = data_set['target'].shape[0] / 3\n",
    "Ytr = data_set['target'][test_set_size:]\n",
    "Xtr = data_set['data'][test_set_size:]\n",
    "validation_set_size = Xtr.shape[0] / 3\n",
    "# Xvd = Xtr[:validation_set_size]\n",
    "# Yvd = Ytr[:validation_set_size]\n",
    "# Xtr = Xtr[validation_set_size:]\n",
    "# Ytr = Ytr[validation_set_size:]\n",
    "Yts = data_set['target'][:test_set_size]\n",
    "Xts = data_set['data'][:test_set_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 s, sys: 898 ms, total: 38.5 s\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_lambda = 1\n",
    "W = pymlearn.linear.train_classifer(Xtr, Ytr, loss='softmax', reg=p_lambda, solver='GD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W = W.keys()[0].get_value()\n",
    "W = W.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 96.16%\n",
      "Accuracy on test: 91.82%\n"
     ]
    }
   ],
   "source": [
    "W = W.reshape(10,-1)\n",
    "print 'Accuracy on train: %0.2f%%' % (accuracy_score(Ytr, pymlearn.linear.classify(W, Xtr)) * 100)\n",
    "print 'Accuracy on test: %0.2f%%' % (accuracy_score(Yts, pymlearn.linear.classify(W, Xts)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38461349,  0.54111484,  0.30777763,  0.29831978,  0.70138548,\n",
       "        0.16032543,  0.28091796,  0.06723132,  0.41531958,  0.00936577,\n",
       "        0.49287225,  0.17751858,  0.61225323,  0.11229339,  0.75713989,\n",
       "        0.72958567,  0.69822749,  0.03293972,  0.88670999,  0.52954358,\n",
       "        0.2047859 ,  0.39220344,  0.95367108,  0.79782938,  0.79187533,\n",
       "        0.46979735,  0.82412274,  0.59995856,  0.41358166,  0.6466326 ,\n",
       "        0.31824963,  0.60498499,  0.05072902,  0.01531144,  0.18921635,\n",
       "        0.02951514,  0.1530959 ,  0.95121525,  0.69496635,  0.55289587,\n",
       "        0.91547142,  0.34546004,  0.1820328 ,  0.53971596,  0.44840406,\n",
       "        0.02931197,  0.07733575,  0.69563447,  0.97969947,  0.4475829 ,\n",
       "        0.67590469,  0.51312345,  0.99754657,  0.93610698,  0.32047171,\n",
       "        0.77078826,  0.80578302,  0.85969954,  0.04284026,  0.37283109,\n",
       "        0.65019889,  0.05191589,  0.66987585,  0.20572214,  0.7336652 ,\n",
       "        0.56952808,  0.88077174,  0.89532144,  0.71793791,  0.92391256,\n",
       "        0.43716746,  0.32926989,  0.53730421,  0.54464485,  0.32095706,\n",
       "        0.13480253,  0.57374872,  0.0630568 ,  0.3416095 ,  0.0904542 ,\n",
       "        0.12437446,  0.30232812,  0.50094497,  0.60916061,  0.95498799,\n",
       "        0.40660639,  0.43393372,  0.2290384 ,  0.27740167,  0.75840626,\n",
       "        0.31108854,  0.76845882,  0.014684  ,  0.63342149,  0.59046798,\n",
       "        0.53374151,  0.46661722,  0.62425285,  0.55016021,  0.35084731,\n",
       "        0.13373833,  0.01719102,  0.18926887,  0.72558453,  0.73116264,\n",
       "        0.18117151,  0.69387271,  0.8265599 ,  0.6536283 ,  0.37682643,\n",
       "        0.15273415,  0.8881986 ,  0.66656349,  0.90418367,  0.67776726,\n",
       "        0.15650615,  0.90078646,  0.67342158,  0.67311275,  0.50242897,\n",
       "        0.76341281,  0.17208825,  0.39326672,  0.72290269,  0.39412624,\n",
       "        0.95126143,  0.3833868 ,  0.01747445,  0.76174228,  0.19253776,\n",
       "        0.8693455 ,  0.57863524,  0.50265801,  0.58992187,  0.77546027,\n",
       "        0.8240626 ,  0.11524756,  0.03337132,  0.2824608 ,  0.6153925 ,\n",
       "        0.44226388,  0.75485748,  0.61196901,  0.86934906,  0.97410059,\n",
       "        0.80863192,  0.53346508,  0.63473136,  0.47125382,  0.9146728 ,\n",
       "        0.12727556,  0.03648012,  0.17897621,  0.90555168,  0.06607607,\n",
       "        0.12716682,  0.13383997,  0.93058277,  0.77230129,  0.65802429,\n",
       "        0.50787852,  0.27295897,  0.76682979,  0.13881765,  0.47052799,\n",
       "        0.00742531,  0.38372216,  0.53511119,  0.5430953 ,  0.69958201,\n",
       "        0.76348435,  0.92754488,  0.97524988,  0.01972129,  0.28220056,\n",
       "        0.29937056,  0.94898523,  0.86443135,  0.22181516,  0.2432063 ,\n",
       "        0.67091796,  0.7406225 ,  0.6195988 ,  0.91037392,  0.81799702,\n",
       "        0.32556872,  0.76287383,  0.24032886,  0.18392248,  0.08333274,\n",
       "        0.39775951,  0.24357406,  0.62208426,  0.13979285,  0.45513075,\n",
       "        0.85319119,  0.18685378,  0.1561472 ,  0.1492882 ,  0.28537174,\n",
       "        0.21551137,  0.60155256,  0.53882536,  0.27085972,  0.95842697,\n",
       "        0.60799695,  0.68993995,  0.11816316,  0.33068876,  0.79884029,\n",
       "        0.3648017 ,  0.26215422,  0.64675824,  0.97015281,  0.77516604,\n",
       "        0.22204142,  0.01853277,  0.4179975 ,  0.42376272,  0.41024084,\n",
       "        0.15607553,  0.62730791,  0.97091669,  0.394651  ,  0.65747596,\n",
       "        0.29186935,  0.502539  ,  0.37045059,  0.82235108,  0.55142608,\n",
       "        0.6174682 ,  0.76048225,  0.21505647,  0.34206278,  0.93858871,\n",
       "        0.71451805,  0.56656073,  0.67731724,  0.20533714,  0.944473  ,\n",
       "        0.3350561 ,  0.47470412,  0.91948282,  0.70423256,  0.34796113,\n",
       "        0.06031336,  0.28128739,  0.04954065,  0.22349712,  0.33337001,\n",
       "        0.59880287,  0.38173807,  0.51534712,  0.65825209,  0.72195377,\n",
       "        0.46096844,  0.50074718,  0.51107087,  0.89007327,  0.8204414 ,\n",
       "        0.54018973,  0.89817619,  0.21235879,  0.36693851,  0.58074334,\n",
       "        0.849695  ,  0.82626861,  0.31095943,  0.74306984,  0.15322177,\n",
       "        0.04327706,  0.51987171,  0.61155672,  0.3479342 ,  0.64721894,\n",
       "        0.53312518,  0.79467548,  0.60498628,  0.25042184,  0.19966487,\n",
       "        0.01153629,  0.58616349,  0.2902426 ,  0.95682073,  0.79955046,\n",
       "        0.83221716,  0.18420594,  0.22318373,  0.22367321,  0.88884999,\n",
       "        0.41635685,  0.75420103,  0.20900303,  0.1830463 ,  0.04347813,\n",
       "        0.3763441 ,  0.09702953,  0.17274414,  0.55747401,  0.97167205,\n",
       "        0.74053069,  0.80081606,  0.04122793,  0.87764263,  0.86960423,\n",
       "        0.57586935,  0.47818524,  0.81066302,  0.51876227,  0.41680671,\n",
       "        0.37523295,  0.96977751,  0.08156674,  0.03019172,  0.15435981,\n",
       "        0.573716  ,  0.86984245,  0.02453387,  0.96838178,  0.44460681,\n",
       "        0.02371515,  0.51055771,  0.93880156,  0.40337474,  0.80627023,\n",
       "        0.35372601,  0.8485375 ,  0.27142352,  0.8509244 ,  0.53224916,\n",
       "        0.50936984,  0.10061654,  0.35005925,  0.35620357,  0.7762061 ,\n",
       "        0.81843311,  0.04629283,  0.49883757,  0.0643314 ,  0.0766899 ,\n",
       "        0.51310732,  0.05508032,  0.23676481,  0.2908633 ,  0.78283392,\n",
       "        0.52726878,  0.72615264,  0.01263524,  0.80924792,  0.1078359 ,\n",
       "        0.5657742 ,  0.1467413 ,  0.37784176,  0.68382806,  0.8790689 ,\n",
       "        0.41898668,  0.3260558 ,  0.54233732,  0.71425894,  0.72958822,\n",
       "        0.28676361,  0.63604265,  0.87209969,  0.23167253,  0.60425366,\n",
       "        0.97419808,  0.50707826,  0.58008792,  0.2584771 ,  0.93476841,\n",
       "        0.2498435 ,  0.45885873,  0.20309685,  0.22161679,  0.04627695,\n",
       "        0.31395229,  0.98586233,  0.27663948,  0.19957822,  0.467561  ,\n",
       "        0.01764527,  0.98090083,  0.60910688,  0.84541063,  0.75603538,\n",
       "        0.34952411,  0.11044733,  0.87710385,  0.13204572,  0.0917283 ,\n",
       "        0.06980636,  0.13641796,  0.67085151,  0.71402048,  0.14450657,\n",
       "        0.15774639,  0.41198599,  0.06249079,  0.56601909,  0.44733006,\n",
       "        0.95320279,  0.19296718,  0.89996772,  0.77321355,  0.83998004,\n",
       "        0.90319517,  0.41972896,  0.47377163,  0.82703442,  0.06506695,\n",
       "        0.27468797,  0.7769147 ,  0.07949892,  0.90519341,  0.15516257,\n",
       "        0.91090656,  0.27364696,  0.25580463,  0.3685751 ,  0.14428578,\n",
       "        0.62330101,  0.19132614,  0.78754474,  0.38230499,  0.84009606,\n",
       "        0.40067099,  0.09515325,  0.37846759,  0.47779087,  0.54772846,\n",
       "        0.29546001,  0.63599767,  0.86013275,  0.3354389 ,  0.92941751,\n",
       "        0.16456787,  0.87517138,  0.64848581,  0.10302968,  0.27352244,\n",
       "        0.2858524 ,  0.385122  ,  0.38405772,  0.19462532,  0.05886724,\n",
       "        0.0600525 ,  0.396558  ,  0.39707795,  0.60967012,  0.22786341,\n",
       "        0.94588491,  0.28258447,  0.60111554,  0.69263519,  0.44830798,\n",
       "        0.79464552,  0.49418946,  0.86389694,  0.07137475,  0.89708631,\n",
       "        0.89801547,  0.12956765,  0.56354958,  0.46399686,  0.23016772,\n",
       "        0.90967325,  0.30898473,  0.19113764,  0.33104172,  0.18759666,\n",
       "        0.75276016,  0.01421394,  0.47809088,  0.22610135,  0.55219397,\n",
       "        0.1820839 ,  0.84328074,  0.827255  ,  0.75519494,  0.9453963 ,\n",
       "        0.17462472,  0.64094461,  0.71922584,  0.08662588,  0.42319702,\n",
       "        0.27479781,  0.45384014,  0.28263405,  0.25865919,  0.15740759,\n",
       "        0.95180397,  0.57594374,  0.7320301 ,  0.81025118,  0.48481966,\n",
       "        0.29998951,  0.75672464,  0.41832886,  0.1225424 ,  0.30198769,\n",
       "        0.90226471,  0.21788368,  0.95487084,  0.75614353,  0.06917246,\n",
       "        0.91537043,  0.93948419,  0.65966188,  0.8910048 ,  0.12911088,\n",
       "        0.81242108,  0.45173729,  0.23702704,  0.30843643,  0.33456927,\n",
       "        0.56020996,  0.75609699,  0.28393235,  0.28504134,  0.28294773,\n",
       "        0.96775824,  0.37344783,  0.14281584,  0.11473231,  0.72931723,\n",
       "        0.11689591,  0.06172511,  0.44908028,  0.74561749,  0.40770488,\n",
       "        0.20882136,  0.09761269,  0.71796081,  0.86531556,  0.55690134,\n",
       "        0.59158958,  0.4197332 ,  0.63897902,  0.86264735,  0.0227456 ,\n",
       "        0.41428479,  0.82491146,  0.38626232,  0.42856603,  0.71714947,\n",
       "        0.15121016,  0.64275921,  0.26080349,  0.63332603,  0.08341322,\n",
       "        0.74189364,  0.50043783,  0.62621699,  0.01848275,  0.80935389,\n",
       "        0.14002291,  0.10318393,  0.03317427,  0.98563567,  0.48430074,\n",
       "        0.09730696,  0.32666319,  0.28284621,  0.22033936,  0.10238775,\n",
       "        0.39687491,  0.52466969,  0.40706977,  0.23867642,  0.53997222,\n",
       "        0.17236471,  0.95737009,  0.04456486,  0.91657799,  0.75711989,\n",
       "        0.2890545 ,  0.22224065,  0.3375039 ,  0.25290116,  0.8919771 ,\n",
       "        0.54541568,  0.25623632,  0.04593459,  0.05570312,  0.44358762,\n",
       "        0.30554684,  0.93638692,  0.23384355,  0.60190213,  0.86969476,\n",
       "        0.0400107 ,  0.56344138,  0.18477255,  0.93051508,  0.83589267,\n",
       "        0.71965863,  0.15155601,  0.29189758,  0.246841  ,  0.13095787,\n",
       "        0.58030183,  0.53579191,  0.77792514,  0.96521513,  0.37706242,\n",
       "        0.00442811,  0.9627498 ,  0.47745175,  0.40795702,  0.58484529,\n",
       "        0.29293031,  0.45069702,  0.44075093,  0.30877921,  0.14139816,\n",
       "        0.30736876,  0.73666637,  0.20281022,  0.22100857,  0.76923374,\n",
       "        0.95313405,  0.9380068 ,  0.99025221,  0.79373345,  0.49632679,\n",
       "        0.50514851,  0.43806369,  0.09973155,  0.7268097 ,  0.09808599,\n",
       "        0.30836806,  0.25894579,  0.04819871,  0.38355202,  0.89427435,\n",
       "        0.73236191,  0.12207663,  0.47618887,  0.0650555 ,  0.91903874,\n",
       "        0.54523784,  0.35820064,  0.16150877,  0.08019131,  0.73751407,\n",
       "        0.59985754,  0.10501589,  0.73387403,  0.24599384,  0.05732379])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 98.16%\n",
      "Accuracy on test: 93.32%\n"
     ]
    }
   ],
   "source": [
    "p_lambda = 0.2\n",
    "clf_ = pymlearn.linear.LinearClassifer(reg=p_lambda, loss='softmax')\n",
    "clf_.fit(Xtr, Ytr)\n",
    "print 'Accuracy on train: %0.2f%%' % (accuracy_score(Ytr, clf_.predict(Xtr)) * 100)\n",
    "print 'Accuracy on test: %0.2f%%' % (accuracy_score(Yts, clf_.predict(Xts)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 98.00%\n",
      "Accuracy on test: 91.82%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.grid_search\n",
    "\n",
    "params_grid = {'loss': ['hinge', 'softmax'], 'penalty': ['L1', 'L2'], \n",
    "                                                 'reg': np.logspace(-2,2,10)}\n",
    "estimator = pymlearn.linear.LinearClassifer()\n",
    "clf_ = sklearn.grid_search.GridSearchCV(estimator, params_grid, cv=[(np.arange(validation_set_size, Xtr.shape[0]), \n",
    "                                                                    np.arange(validation_set_size))], n_jobs=4)\n",
    "clf_.fit(Xtr, Ytr)\n",
    "\n",
    "print 'Accuracy on train: %0.2f%%' % (accuracy_score(Ytr, clf_.predict(Xtr)) * 100)\n",
    "print 'Accuracy on test: %0.2f%%' % (accuracy_score(Yts, clf_.predict(Xts)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172932330827067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'hinge', 'penalty': 'L1', 'reg': 0.077426368268112694}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkopersk/anaconda2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = clf_.params\n",
    "for i in range(W.shape[0]):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    v = W[i,:-1].reshape((8,8))\n",
    "    ax.matshow(v, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_s = W.copy()\n",
    "W_s[W_s < 1e-2] = 0\n",
    "W_orig = W.copy()\n",
    "W = W_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
